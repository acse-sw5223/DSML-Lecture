{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "172eecb7",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1-cL5eOpEsbuIEkvwW2KnpXC12-PAbamr\" style=\"Width:1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a7357f",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1fyePzwUvVF9OBK2q9-t9f8fojx6Sp0Es\" style=\"Width:250px, height:250px\">\n",
    "\n",
    "# Movie Reviews\n",
    "\n",
    "In this and the following exercise, you will use the famous <a href=\"https://www.imdb.com/\">IMDB movie dataset</a> as saved on <a href=\"https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\">Kaggle</a>. The Kaggle dataset contains 50K movies, but this tends to crash your kernel and be slow. The version I give you today has been downsampled to 25k reviews..\n",
    "\n",
    "Your task is is to classify movie reviews as positive or negative. You will:\n",
    "\n",
    "- Preprocess the reviews (remove punctuation and lower case)\n",
    "- Vectorize a Bag of words\n",
    "- Train and score a Naive Bayes model\n",
    "\n",
    "Let's start by importing the data. We will use `cross_validation` today so we won't worry too much about a test set (though for serious NLP you would want to have one!)\n",
    "\n",
    "P.S. Look on the photo at the spelling of results. Dall-E is getting better in 2023, but not yet perfect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c71a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbta.utils import download_data\n",
    "download_data(id='1DtuD7LtrfUfGSZioocYZvTzkpvLwgqwA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63744c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"raw_data/IMDB_dataset_25k.csv\")\n",
    "\n",
    "# This data is too large for most of your systems, so we will take only 10% of the dataset:\n",
    "data = data.sample(frac=0.1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac527914",
   "metadata": {},
   "source": [
    "The dataset is made up of positive and negative movie reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e7744",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Create a new column in `data` called `clean_text`. This will contain a cleaned version of the `review`, where you will remove punctuation,  lower case the text, remove digits, remove english stop-words, lemmatiaze your text, and tokenize it. We will preserve the text as a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a5c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's make sure that the stopwords from NLTK are downloaded on your system:\n",
    "\n",
    "from nltk import download\n",
    "\n",
    "download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4746e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reduce the memory footprint\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea6a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def prepare_text(text):\n",
    "    # remove punctuations and digits \n",
    "    text = ''.join([char for char in text if char not in string.punctuation]).\\\n",
    "            lower()\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    # stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = word_tokenize(text) \n",
    "    \n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in word_tokens if not w in stop_words])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aba99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data.review.apply(prepare_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a927f2b8",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Test your code\n",
    "\n",
    "Note: this only tests if you achieve the mandated **precision** and **recall** on an unseen dataset. It does not check the quality of your code or the completeness of your answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e4fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('check_data',\n",
    "                         sentence = data.clean_text[0],\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91215b52",
   "metadata": {},
   "source": [
    "## Bag-of-Words modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc9212",
   "metadata": {},
   "source": [
    "Using `cross_validate`, score a Multinomial Naive Bayes model trained on a Bag-of-Word representation of the texts. Save its test accuracy as a variable named `bow_accuracy`. <details><summary>hint</summary>Use a `CountVectorizer`!</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_v = vectorizer.fit_transform(data.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1df402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "y = data.sentiment.apply(lambda x: x=='positive')\n",
    "\n",
    "cross_val = cross_validate(MultinomialNB(),X_v,y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_accuracy = cross_val['test_score'].mean()\n",
    "bow_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a6658b",
   "metadata": {},
   "source": [
    "## N-gram modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b7dbe",
   "metadata": {},
   "source": [
    "üëá Using `cross_validate`, score a Multinomial Naive Bayes model trained on a 2-gram Bag-of-Word representation of the texts. You will use again the `CountVectorizer()` class but need to choose the right parameters. Save the test accuracy of your cross_validation as a variable named `ng_accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3639a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range = (2,2))\n",
    "\n",
    "X_v = vectorizer.fit_transform(data.clean_text)\n",
    "\n",
    "pd.DataFrame(X_v.toarray(),columns = vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val = cross_validate(MultinomialNB(),X_v,y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c005e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_accuracy = cross_val['test_score'].mean()\n",
    "ng_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa685a4",
   "metadata": {},
   "source": [
    "## Assessing your model\n",
    "\n",
    "Which model performed better, and why do you think that is?\n",
    "\n",
    "<details><summary>Solution</summary>We would expect the N-Gram model to outperform your Bag-of-Words by a small margin. However, because of our reduced dataset, this is not really the case here. N-Grams are normally better (though more computationally costly) because they capture the context of the words around a single token. This give more meaning to words that could otherwise have different meaning depending on the context. You will see this furhter in deep-learning, when you learn about the attention mechanism for `Transformers`, the de-facto go-to architecture for NLP today.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff47b65",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Test your code\n",
    "\n",
    "Note: this only tests if you achieve the mandated **precision** and **recall** on an unseen dataset. It does not check the quality of your code or the completeness of your answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e16cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('model_performance',\n",
    "                         bow_model = bow_accuracy,\n",
    "                         ng_model = ng_accuracy\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc66213a",
   "metadata": {},
   "source": [
    "# Saving your data\n",
    "\n",
    "To save time, we will reuse the preprocessed data in the next exercise. Therefore, save the `data` dataframe as a `csv` file on the path `../02-Tuning-for-NLP/raw_data` as `processed_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../02-Tuning-for-NLP/raw_data/processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6862aa",
   "metadata": {},
   "source": [
    "# üèÅ Finished!\n",
    "\n",
    "Well done! <span style=\"color:teal\">**Push your exercise to GitHub**</span>, and move on to the next one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
