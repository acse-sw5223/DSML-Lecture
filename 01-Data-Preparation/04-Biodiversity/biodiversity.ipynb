{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4819a9b",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1-d7H1l1lJ28_sLcd9Vvh_N-yro7CJZcZ\" style=\"Width:1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31609254",
   "metadata": {},
   "source": [
    "# Golden Plains Roadside Biodiversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1968dcc",
   "metadata": {},
   "source": [
    "This is your first data problem! Remember, \"Data Problems\" are a little bit less directed than the skills problem. They are here to encourage you to use your critical thinking when dealing with data. It is also a better reflection of the type of problems you will encounter during your assessed coursework at the end of the course. Make sure you understand what you have done in the previous exercises, and apply it here. Also, ***get into the habit of maintaining a  clean, working notebook***. This will be a key assessment criteria for your marked coursework later next week, so take this opportunity (and further ones) to learn how to do this. This includes using `markdown` cells for comments and observations, making sure your code can run from top to bottom when using `run all cells` from the menu, and of course, keeping a **clean code** practice. It also also a good idea, once you are done with your work, to put all of your `import` statements at the top of the notebook: this way, it is clear what is imported in the entire notebook and allows you to focus on your more important code below.\n",
    "\n",
    "Here is a little bit of information on the data you are given. Golden Plains Shire (Australia) is responsible for managing 1834 kilometres of road reserves. Road reserves are not only used for transport but also act as service corridors, in fire prevention, recreation, and occasionally agricultural pursuits. Native vegetation on roadsides is important flora and fauna habitat and landscape character.\n",
    "\n",
    "In 2014, Golden Plains Shire acquired funding through the Victorian Adaptation and Sustainability Partnership (VASP) to undertake Councils ‚ÄòBuilding Adaptive Capacity on Roadsides‚Äô project. The Project was designed to identify significant environmental assets on roadsides, improve roadside management practices and reduce Council‚Äôs risk of potential breaches against Federal and State environmental legislation. \n",
    "\n",
    "The council made this <a href='https://data.gov.au/data/dataset/golden-plains-roadside-biodiversity'>dataset available here</a>.<br>\n",
    "![plain](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/Mount_Conner%2C_August_2003.jpg/375px-Mount_Conner%2C_August_2003.jpg)\n",
    "<br>\n",
    "\n",
    "üéØ Today, you will work with a simplified version of this real dataset. The dataset contains a number of biodiversity observations including one on tree size (`RCACTreesS`). This exercise consists of the data preparation and modelling techniques you have learnt: our goal is to predict via linear regression the `RCACTreesS` using the available features and obtain a good score.\n",
    "\n",
    "‚ö†Ô∏è This is a long exercises, which will require you to think about the data. Don't hesitate to plot things - if you need to use algorithm that use a `random_seed` such as `train_test_split` or others, remember to always use the value `42` so your results can be compared to the proposed solution. If you get stuck, ask a TA!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3755da14",
   "metadata": {},
   "source": [
    "# Part I: Ensuring Generalization and EDA\n",
    "\n",
    "In this first part, do the following:\n",
    "1. üëá Load the data into this notebook as a pandas dataframe named `df`, and display its first 5 rows.\n",
    "2. Check for and drop duplicates\n",
    "3. We will use the `RCACTreesS` as our target variable (`y`) and all other columns as our features (`X`).\n",
    "4. Split the dataset into 80%/20% train/test splits (use a `random_state=42`) to create your `X_train`, `X_test`, `y_train`, `y_test` (see above regarding the `y`).\n",
    "5. **Using only the X_train**, spend some time exploring the dataset, for instance looking at the different columns it contains, it's data types, any missing values. Check for correlations between features, and draw some plots. At the end of this EDA stage, you should have a good idea of what the data is. Try to keep this notebook cleanly organised, using `Markdown` cells to put comments for yourself (and your TAs) about your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "561b1862",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/shiyunwa/Documents/dsml4pe-student-pack-acse-sw5223/01-Data-Preparation/04-Biodiversity/biodiversity.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shiyunwa/Documents/dsml4pe-student-pack-acse-sw5223/01-Data-Preparation/04-Biodiversity/biodiversity.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnbta\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m download_data\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/shiyunwa/Documents/dsml4pe-student-pack-acse-sw5223/01-Data-Preparation/04-Biodiversity/biodiversity.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m download_data(\u001b[39mid\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m19qi8xMUaamIAX8KcZproR33c2JQcOAul\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/site-packages/nbta/utils.py:54\u001b[0m, in \u001b[0;36mdownload_data\u001b[0;34m(id, google_drive, zip_name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     url\u001b[39m=\u001b[39m\u001b[39mid\u001b[39m\n\u001b[0;32m---> 54\u001b[0m wget\u001b[39m.\u001b[39mdownload(url)\n\u001b[1;32m     56\u001b[0m \u001b[39mwith\u001b[39;00m zipfile\u001b[39m.\u001b[39mZipFile(zip_name, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m,) \u001b[39mas\u001b[39;00m zip_ref:\n\u001b[1;32m     57\u001b[0m     zip_ref\u001b[39m.\u001b[39mextractall()\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/site-packages/wget.py:526\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(url, out, bar)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    525\u001b[0m     binurl \u001b[39m=\u001b[39m url\n\u001b[0;32m--> 526\u001b[0m (tmpfile, headers) \u001b[39m=\u001b[39m ulib\u001b[39m.\u001b[39murlretrieve(binurl, tmpfile, callback)\n\u001b[1;32m    527\u001b[0m filename \u001b[39m=\u001b[39m detect_filename(url, out, headers)\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m outdir:\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/urllib/request.py:241\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m url_type, path \u001b[39m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m contextlib\u001b[39m.\u001b[39mclosing(urlopen(url, data)) \u001b[39mas\u001b[39;00m fp:\n\u001b[1;32m    242\u001b[0m     headers \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39minfo()\n\u001b[1;32m    244\u001b[0m     \u001b[39m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[39m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[1;32m    527\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39merror(\n\u001b[1;32m    635\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttp\u001b[39m\u001b[39m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[1;32m    637\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/urllib/request.py:557\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    555\u001b[0m     http_err \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    556\u001b[0m args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, proto, meth_name) \u001b[39m+\u001b[39m args\n\u001b[0;32m--> 557\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_chain(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    558\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m    559\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/urllib/request.py:749\u001b[0m, in \u001b[0;36mHTTPRedirectHandler.http_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    746\u001b[0m fp\u001b[39m.\u001b[39mread()\n\u001b[1;32m    747\u001b[0m fp\u001b[39m.\u001b[39mclose()\n\u001b[0;32m--> 749\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mopen(new, timeout\u001b[39m=\u001b[39mreq\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[1;32m    527\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39merror(\n\u001b[1;32m    635\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttp\u001b[39m\u001b[39m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[1;32m    637\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_chain(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/ese-msc/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "from nbta.utils import download_data\n",
    "download_data(id='19qi8xMUaamIAX8KcZproR33c2JQcOAul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e8749",
   "metadata": {},
   "source": [
    "# Part II: Missing values and scaling\n",
    "\n",
    "Now do the following:\n",
    "1. Drop features with >30% missing values\n",
    "2. Imput `RoadWidthM`, `PowerlineD` and `Trees` using the most appropriate strategy <details>\n",
    "    <summary> üí° Hint </summary>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è Look at the datatype of <code>PowerlineD</code> and the distribution of the data using the <code>.unique()</code> method. Although <code>PowerlineD</code> is a numeric value, it clearly only has discrete distribution: what would be a logical value to impute? The same applies to <code>Trees</code> and <code>RoadWidthM</code> but for a different reason: they are a continuous variable but there is clearly one value that dominates the distribution: it makes sense to assume that the `nan` represent this most frequent value. So you can impute both of these variables at the same time.\n",
    "</details> \n",
    "3. Imput `Locality` and `EVNotes` <details>\n",
    "    <summary>üí° Hint </summary>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è Clearly <code>Locality</code> refers to the name of the county or region where the data comes from. We could impute the most frequent locality, but this would induce some errors. In this case, the best strategy is simply to replace the <code>nan</code> by something meaningful such as 'not known'. <code>EVCNotes</code> is somewhat similar: the <code>nan</code> values indicate that no notes exist, so we should replace them by 'no notes'.\n",
    "</details>\n",
    "4. Impute `SoilType` and `LandformLS` <details>\n",
    "    <summary>üí° Hint </summary>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è These two are tricky. They both are string values, and they both have two classes that are very common. On a real project, a good data scientist will study what those codes means <a href=\"http://vro.agriculture.vic.gov.au/dpi/vro/vrosite.nsf/pages/landform_land_systems_rees/$FILE/TECH_56%20ch6.pdf\"> by refering to the government publication</a>. In an ideal world we would explore different strategies for imputation (we will see this later in the course). However here we need to decide based on little evidence. Because we have no information, and because there is not a clear majority in either soil or landform classes, the best is to impute 'SoilTypeNA' and 'LandFormLSNA' as as a new class.\n",
    "</details>\n",
    "5. Imput `CanopyCont` <details>\n",
    "    <summary>üí° Hint </summary>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è If you do a <code>value_counts()</code> on <code>CanopyCont</code> you will see that this consists of 4 numerical variables, and 5 categorical variables. It is clear that this column has two different encoding for the same concept: how continuous is the canopy? The easiest is to transform this into a numerical column by doing the following replacements: 'none'=0, 'sparse'=1, 'patchy'=2, 'continous' or 'c' = 3. You probably want to use a python dictionary and an <code>apply()</code> function to do that, and remember to cast your values to an <code>int</code> or a <code>float</code>!\n",
    "</details>\n",
    "6. Scale all of your numerical features using an appropriate scaler. Check their distribution before deciding on your scaling strategy! <details>\n",
    "    <summary>üí° Hint </summary>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è <code>WidthVarie</code>, & <code>Powerline</code> are clearly binary variable ([0,1]). They should not be scaled, but rater can optionally be encoded using a <code>CategoricalEncoder</code>. Simply leave them as they are. All other numerical features are non-guassian so a `RobustScaler` is probably the most appropriate.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af2d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f035eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d64cc59",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81238080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('missing_values',\n",
    "                         dataset = X_train)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baddaf4e",
   "metadata": {},
   "source": [
    "### Testing your scaling\n",
    "Test your code below for scaling before proceeding to ensure all worked well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c71e4d",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49763d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('scaling',\n",
    "                         dataset = X_train,\n",
    "                         features = numerical_columns\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44907bc7",
   "metadata": {},
   "source": [
    "# Part III: Encoding and Modelling\n",
    "\n",
    "All that is left to do now is deal with categorical data, and then use this to build a simple model.\n",
    "\n",
    "# Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd33ed1",
   "metadata": {},
   "source": [
    "üëá Investigate the non-numerical features that require encoding, and apply 'One hot encoding'. To ensure that we do not end up with an explosion of feature, we will retain only categorical features with <15 unique values for encoding. \n",
    "\n",
    "So your task is the following:\n",
    "\n",
    "1. Identify programmatically all of the categorical features that have <15 unique categories and require 'One Hot encoding'\n",
    "2. In the dataframe, replace the original features by their encoded version(s). Make sure to drop the original features, as well as the features with >15 unique categories from `X_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d987a47b",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d7edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('encoding',\n",
    "                         dataset = X_train)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77333658",
   "metadata": {},
   "source": [
    "# Base Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02831468",
   "metadata": {},
   "source": [
    "All we need now is to cross validate  a Linear regression model with our `X_train` and `y_train` using `cv=5`. Save its score under variable name `base_model_score`. However, if you do this you will see that we obtain a very low `r2`. This is because not all of the features we have selected are useful - we will talk more about this in a couple of days. So instead, train your model using only the top features that have a correlation with your `y_train` > 0.05.  <details><summary>üí° Hint </summary>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è If you are unsure how to do this, check the documentation for the `corr()` function in pandas. Also, you will need to add group the `y_train` and the `X_train` in the same pandas object to do that.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c7c83b",
   "metadata": {},
   "source": [
    "### ‚òëÔ∏è Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff181807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('base_model',\n",
    "                         score = base_model_score\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c087b3e",
   "metadata": {},
   "source": [
    "# üèÅ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
